{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import pandasql as ps\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transaction_df = pd.read_csv('transaction.csv')\n",
    "dtypes = transaction_df.dtypes\n",
    "col_names = ','.join([col.replace(\" \",\"\") for col in transaction_df.columns])\n",
    "transaction_df.columns = [col.replace(\" \",\"\") for col in transaction_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template:\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_template = \"\"\"\n",
    "Role: You are a SQL expert. \n",
    "\n",
    "Context: A sql table has the following columns: {col_names}. Write an sql command for the following query:\n",
    "\n",
    "Output: Return only the sql query and assume the table name as df\n",
    "\"\"\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",generic_template),(\"user\",\"{text}\")\n",
    "    ]\n",
    ")\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm|parser\n",
    "query = chain.invoke({\n",
    "    \"col_names\":col_names,\n",
    "    \"text\":\"Frequency distribution of the number of transaction by account number\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = transaction_df\n",
    "print(f\"Query: {query}\")\n",
    "print(ps.sqldf(query, locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qroq_api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ollama' has no attribute 'list_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mollama\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_models\u001b[49m()\n\u001b[1;32m      3\u001b[0m models\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ollama' has no attribute 'list_models'"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "models = ollama.list_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Ollama' from 'langchain' (/Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages/langchain/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Ollama\n\u001b[1;32m      2\u001b[0m ollama_client \u001b[38;5;241m=\u001b[39m Ollama()\n\u001b[1;32m      3\u001b[0m model_list \u001b[38;5;241m=\u001b[39m ollama_client\u001b[38;5;241m.\u001b[39mlist_models()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Ollama' from 'langchain' (/Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages/langchain/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain import Ollama\n",
    "ollama_client = Ollama()\n",
    "model_list = ollama_client.list_models()\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (0.4.6)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from ollama) (2.10.4)\n",
      "Requirement already satisfied: anyio in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/soumajitbiswas/Desktop/natural-language-processing/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    "  headers={'x-some-header': 'some-value'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = client.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(model='deepseek-r1:8b', modified_at=datetime.datetime(2025, 1, 22, 7, 44, 38, 581626, tzinfo=TzInfo(+05:30)), digest='28f8fd6cdc677661426adab9338ce3c013d7e69a5bea9e704b364171a5d61a10', size=4920738407, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_K_M'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list['models'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_MODEL_LIST = [model['model'] for model in model_list['models']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deepseek-r1:8b', 'llama3.2:latest']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLLAMA_MODEL_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
